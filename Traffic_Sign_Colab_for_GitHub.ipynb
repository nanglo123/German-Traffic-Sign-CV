{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCMuzK1Ukp9mGmt65knjR8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd96f9698d454c92aec9640c95e2b22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba1274028ee9487ea2d3c4bd6a07081b",
              "IPY_MODEL_285500f48bfd4deb814695769b65ad1d",
              "IPY_MODEL_0d1f76f7ee9a4b25bdf5dc889052844a"
            ],
            "layout": "IPY_MODEL_f96c50e09b3f463a8fadd866ac44a7ec"
          }
        },
        "ba1274028ee9487ea2d3c4bd6a07081b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_314cead0203745329eb205ee89332d7b",
            "placeholder": "​",
            "style": "IPY_MODEL_511045e3afa34789bdf1844f526fe661",
            "value": "  8%"
          }
        },
        "285500f48bfd4deb814695769b65ad1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24717b7cd6394dc1abe1cc8e711333bf",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4632362dc15d4e919ec9924ad44752fb",
            "value": 2
          }
        },
        "0d1f76f7ee9a4b25bdf5dc889052844a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab032c17d34b4387acf591dbb6b3f190",
            "placeholder": "​",
            "style": "IPY_MODEL_e04e14c6fb1d4323948076a47a0989c4",
            "value": " 2/25 [15:23&lt;2:30:43, 393.18s/it]"
          }
        },
        "f96c50e09b3f463a8fadd866ac44a7ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314cead0203745329eb205ee89332d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "511045e3afa34789bdf1844f526fe661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24717b7cd6394dc1abe1cc8e711333bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4632362dc15d4e919ec9924ad44752fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab032c17d34b4387acf591dbb6b3f190": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e04e14c6fb1d4323948076a47a0989c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nanglo123/German-Traffic-Sign-CV/blob/main/Traffic_Sign_Colab_for_GitHub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Import all libraries and frameworks needed"
      ],
      "metadata": {
        "id": "_VKC7OvyTQ-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!pip install torchinfo "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT68XKagj63j",
        "outputId": "89308767-655f-4720-b357-dd65a53764ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.0+cu118)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os \n",
        "import csv\n",
        "import shutil \n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "import torchmetrics\n",
        "import torch\n",
        "from torch import nn \n",
        "from torch.utils.data import Dataset,DataLoader, Subset\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from google.colab import files \n",
        "from pathlib import Path\n",
        "from tqdm.auto import tqdm"
      ],
      "metadata": {
        "id": "j36OabSBj9G3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aUd0U-YckQAy",
        "outputId": "e528b3c9-50a0-4682-b941-13758acd2983"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Download and unzip data"
      ],
      "metadata": {
        "id": "GTQVZP-iTU_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#upload kaggle.json file \n",
        "files.upload()\n",
        "\n",
        "!pip install kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "5btIvFYRkRUY",
        "outputId": "4d2bf943-875b-407a-fc53-b2d9e6c651c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d9b9aa84-1608-4dc2-b6ae-ea913aaa2ff4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d9b9aa84-1608-4dc2-b6ae-ea913aaa2ff4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create data folder and download the dataset from Kaggle \n",
        "data_folder = Path('Data')\n",
        "if data_folder.exists():\n",
        "  print('Folder Created')\n",
        "else:\n",
        "  data_folder.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "\n",
        "!kaggle datasets download meowmeowmeowmeowmeow/gtsrb-german-traffic-sign -p 'Data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XL_xzK_-yLP",
        "outputId": "51d08565-fff2-47cb-86e2-22570d75eb8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading gtsrb-german-traffic-sign.zip to Data\n",
            "100% 611M/612M [00:16<00:00, 44.3MB/s]\n",
            "100% 612M/612M [00:16<00:00, 39.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Unzip downloaded zip file \n",
        "with zipfile.ZipFile('/content/Data/gtsrb-german-traffic-sign.zip', \"r\") as zip_ref:\n",
        "  print(f\"Unzipping traffic {data_folder}\")\n",
        "  zip_ref.extractall('/content/Data/') \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVaqIXxn-58l",
        "outputId": "fdc127b3-7c3e-4fc9-efe5-2d205f2bdcc3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipping traffic Data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Format the Data"
      ],
      "metadata": {
        "id": "zKHsJf73TXF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test directories paths\n",
        "#Currently the downloaded dataset does not have folders for each class for test data (i.e. all test images from all classes are in 1 folder)\n",
        "  #Need in format specified below to make compatiable with ImageFolder object from torchvision library \n",
        "    #Test\n",
        "      #Class 1\n",
        "        #Picture of Class 1\n",
        "      #Class 2\n",
        "        #Picture of Class 2 \n",
        "  #Have to fix the problem in later cells \n",
        "\n",
        "train_dir = data_folder / 'Train'\n",
        "test_dir_with_label = data_folder/'testwithfolders'\n",
        "\n",
        "\n",
        "#Create test directory with sub directories for each class, the Train directory from the dataset has sub directories for each class so it does not need to be created\n",
        "if not test_dir_with_label.exists():\n",
        "  test_dir_with_label.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "\n",
        "#Create list of all class names from the already established train directory (e.g. 1,2,3,4,..., 43)\n",
        "class_names = list(os.scandir(train_dir))\n",
        "\n",
        "\n",
        "#for each class name in the list of class names\n",
        "  #Create a class folder in the test directory with the title of the sub-directory/folder equal to the class name  \n",
        "for dir_entry in class_names:\n",
        "  test_class_folders = test_dir_with_label / str(dir_entry.name)\n",
        "  if not test_class_folders.exists():\n",
        "    test_class_folders.mkdir(parents=True,exist_ok=True)\n"
      ],
      "metadata": {
        "id": "h3xCrBKb-_PU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#read 'test.csv' meta data file\n",
        "  #populate the list 'list_id' with the assigned class for each image in the test dataset listed in the 'test.csv' file by turning the csv file into a pd dataframe\n",
        "  #the 'test.csv' file lists the meta data for each image in numerical order (i.e. information listed for the image '0000.png' listed first and then info for photo '0001.png')\n",
        "    \n",
        "\n",
        "list_of_class_id = None\n",
        "with open(data_folder / 'Test.csv', newline='') as csvfile:\n",
        "  df = pd.read_csv(csvfile)\n",
        "  list_of_class_id = list(df['ClassId'])\n",
        "\n"
      ],
      "metadata": {
        "id": "reCY5co_Bajn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pathway to the existing unformatted Test folder with all test images\n",
        "#Create a list containing path to all test images sorted in numerical order\n",
        "  #(i.e. first element of list is image '0000.png' and second element is '0001.png')\n",
        "filenames = None\n",
        "test_dir_no_labels = data_folder/'Test'\n",
        "image_path_list = sorted(list(test_dir_no_labels.glob(\"*.png\")))\n",
        "\n",
        "\n",
        "#Get the class number (e.g. 5,7,23)\n",
        "#Create pathway to correct class folder in new test directory\n",
        "#Move the path of the image in 'image_path_list' to the correct class folder in new test directory\n",
        "\n",
        "#NOTE: Can cast PosixPath objects as strings just get the name of a directory\n",
        "try:\n",
        "  for pic,i in zip(image_path_list,range(len(image_path_list))):\n",
        "    class_label = list_of_class_id[i]\n",
        "    test_picture_folder_with_label = test_dir_with_label / str(class_label)\n",
        "    shutil.move(str(pic),test_picture_folder_with_label)\n",
        "except:\n",
        "  print('Already moved that picture to the correct class folder in the new test directory')\n",
        "    "
      ],
      "metadata": {
        "id": "SougBji3DZIn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dictionary containing all class number/label to class name key-value pairings \n",
        "classes_dict = { 0:'Speed limit (20kmh)',\n",
        "            1:'Speed limit (30kmh)', \n",
        "            2:'Speed limit (50kmh)', \n",
        "            3:'Speed limit (60kmh)', \n",
        "            4:'Speed limit (70kmh)', \n",
        "            5:'Speed limit (80kmh)', \n",
        "            6:'End of speed limit (80kmh)', \n",
        "            7:'Speed limit (100kmh)', \n",
        "            8:'Speed limit (120kmh)', \n",
        "            9:'No passing', \n",
        "            10:'No passing veh over 3.5 tons', \n",
        "            11:'Right-of-way at intersection', \n",
        "            12:'Priority road', \n",
        "            13:'Yield', \n",
        "            14:'Stop', \n",
        "            15:'No vehicles', \n",
        "            16:'Veh > 3.5 tons prohibited', \n",
        "            17:'No entry', \n",
        "            18:'General caution', \n",
        "            19:'Dangerous curve left', \n",
        "            20:'Dangerous curve right', \n",
        "            21:'Double curve', \n",
        "            22:'Bumpy road', \n",
        "            23:'Slippery road', \n",
        "            24:'Road narrows on the right', \n",
        "            25:'Road work', \n",
        "            26:'Traffic signals', \n",
        "            27:'Pedestrians', \n",
        "            28:'Children crossing', \n",
        "            29:'Bicycles crossing', \n",
        "            30:'Beware of ice or snow',\n",
        "            31:'Wild animals crossing', \n",
        "            32:'End speed + passing limits', \n",
        "            33:'Turn right ahead', \n",
        "            34:'Turn left ahead', \n",
        "            35:'Ahead only', \n",
        "            36:'Go straight or right', \n",
        "            37:'Go straight or left', \n",
        "            38:'Keep right', \n",
        "            39:'Keep left', \n",
        "            40:'Roundabout mandatory', \n",
        "            41:'End of no passing', \n",
        "            42:'End no passing veh > 3.5 tons' }\n",
        "\n"
      ],
      "metadata": {
        "id": "pfe3maPQFfWt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rename class folders in train and test directories with the class label instead\n",
        "  #(e.g. 1 -> Straight Ahead Sign)\n",
        "\n",
        "#This turns the ordering of the class files in both the test and train directory into alphabetically ordered ones based on class label instead of class number\n",
        "  #(e.g. 0 -> 1 -> 2 could now become 2-> 0 -> 1 if class label for class 2 is first alphabetically)\n",
        "  #Have to keep this in mind when preparing list of class labels for the Gradio app because we cannot just read off the folder/class label names in the train or test directory\n",
        "    #Have to reorder to match class folder order when data first imported before renaming later\n",
        "for train_class_dir in os.listdir(train_dir):\n",
        "  try:\n",
        "    train_class_name = classes_dict[int(train_class_dir)]\n",
        "  except ValueError:\n",
        "    continue\n",
        "  os.rename(os.path.join(train_dir, train_class_dir), os.path.join(train_dir, train_class_name))\n",
        "\n",
        "for class_dir in os.listdir(test_dir_with_label):\n",
        "  try:\n",
        "    class_name = classes_dict[int(class_dir)]\n",
        "  except ValueError:\n",
        "    continue\n",
        "  os.rename(os.path.join(test_dir_with_label, class_dir), os.path.join(test_dir_with_label, class_name))"
      ],
      "metadata": {
        "id": "riKMQ-aeHziY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove unecessary/duplicate/empty files and folders after all data is properly formatted \n",
        "!rm -r Data/Meta\n",
        "!rm -r Data/test\n",
        "!rm -r Data/train\n",
        "!rm -r Data/meta\n",
        "!rm Data/gtsrb-german-traffic-sign.zip\n",
        "\n",
        "#Can remove this after moving all test images from this directory into proper test directory \n",
        "!rm -r Data/Test\n",
        "\n",
        "\n",
        "#Rename 'testwithfolders' directory containing properly formatted test data\n",
        "!mv Data/testwithfolders Data/Test"
      ],
      "metadata": {
        "id": "g8OqSZIODpgu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create path variable for new Test directory\n",
        "test_dir = data_folder/'Test'"
      ],
      "metadata": {
        "id": "1nRYLqK-NMBm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create train and test loaders"
      ],
      "metadata": {
        "id": "u_zMDayTTZa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create train and test datasets and loaders with fixed BATCH_SIZE\n",
        "BATCH_SIZE = 32\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(32,32)),\n",
        "    transforms.ToTensor(),\n",
        "  \n",
        "])\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize(size=(32,32)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "train_set = ImageFolder(root=train_dir,transform=train_transforms)\n",
        "train_loader = DataLoader(dataset=train_set,batch_size=BATCH_SIZE,shuffle=True)\n",
        "\n",
        "test_set = ImageFolder(root=test_dir,transform=test_transforms)\n",
        "test_loader = DataLoader(dataset=test_set,batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "FLIQPNhINCkJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define the neural network class"
      ],
      "metadata": {
        "id": "ZAvC4pgoTb9F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "zTQSSGXTwxem"
      },
      "outputs": [],
      "source": [
        "\n",
        "class CNNTraffic(nn.Module):\n",
        "    def __init__(self,input_shape:int,output_shape:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = input_shape, out_channels = 32, kernel_size=5, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=5, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 2),\n",
        "          nn.Dropout(p=.25)\n",
        "          )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 2),\n",
        "          nn.Dropout(p=.25))\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=3136,out_features=256),\n",
        "          nn.Dropout(p=.5),\n",
        "          nn.Linear(in_features=256,out_features=output_shape))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "      return self.fc(self.layer2(self.layer1(x)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the model with correct number of input_shape and output_shape with its loss function and optimzier as well \n",
        "\n",
        "sample,label =  next(iter(train_set))\n",
        "color_channels = sample.shape[0]\n",
        "\n",
        "output_length = len(train_set.classes)\n",
        "\n",
        "\n",
        "m2 = CNNTraffic(input_shape = color_channels, output_shape=output_length).to(device)\n",
        "opt = torch.optim.Adam(params=m2.parameters(), lr=.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "JscjmBlCOvXT"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create path to save model \n",
        "models_save_path = Path('Saved Models')\n",
        "if not models_save_path.exists():\n",
        "  models_save_path.mkdir(parents=True,exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "NwyoRhbSj2nU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Define train and test steps"
      ],
      "metadata": {
        "id": "_c5tMK-hTfmT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_step(model:nn.Module,\n",
        "               opt:torch.optim,\n",
        "               loss_fn:nn.Module,\n",
        "               train_dataloader:torch.utils.data.DataLoader,\n",
        "               device:str):\n",
        "  \n",
        "  model.train()\n",
        "  train_loss,train_acc = 0,0\n",
        "  for X,y in train_dataloader:\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    train_logit = model(X)\n",
        "\n",
        "\n",
        "    #these loss and acc metrics are being computed per batch in loop, not per sample\n",
        "    loss = loss_fn(train_logit,y)\n",
        "\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    train_pred_labels = torch.argmax(torch.softmax(train_logit,dim=1),dim=1)\n",
        "\n",
        "    train_acc += (train_pred_labels==y).sum().item()/len(y)\n",
        "\n",
        "  #get average loss and acc per batch\n",
        "  train_loss /= len(train_dataloader)\n",
        "  train_acc /= len(train_dataloader)\n",
        "\n",
        "  return train_loss,train_acc\n",
        "\n",
        "def test_step(model:nn.Module,\n",
        "               loss_fn:nn.Module,\n",
        "               test_dataloader:torch.utils.data.DataLoader,\n",
        "               device:str):\n",
        "  model.eval()\n",
        "  test_loss,test_acc = 0,0\n",
        "  with torch.inference_mode():\n",
        "    for X,y in test_dataloader:\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "\n",
        "      test_logit = model(X)\n",
        "\n",
        "      loss = loss_fn(test_logit,y)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "\n",
        "    \n",
        "      test_pred_labels = torch.argmax(torch.softmax(test_logit,dim=1),dim=1)\n",
        "\n",
        "      test_acc += (test_pred_labels==y).sum().item()/len(y)\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "  return test_loss,test_acc"
      ],
      "metadata": {
        "id": "hAGlK4Z7PdKy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Take in various parameters required for training and test steps\n",
        "def train(model: torch.nn.Module, \n",
        "          train_dataloader: torch.utils.data.DataLoader, \n",
        "          test_dataloader: torch.utils.data.DataLoader, \n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          device = device,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "    \n",
        "    # 2. Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": []\n",
        "    }\n",
        "    \n",
        "    # 3. Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                           train_dataloader=train_loader,\n",
        "                                           loss_fn=loss_fn,\n",
        "                                           opt=optimizer,\n",
        "                                           device = device)\n",
        "        \n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "            test_dataloader=test_loader,\n",
        "            loss_fn=loss_fn,\n",
        "            device = device)\n",
        "        \n",
        "        # 4. Print out what's happening\n",
        "        print(\n",
        "            f\"Epoch: {epoch+1} | \"\n",
        "            f\"train_loss: {train_loss:.4f} | \"\n",
        "            f\"train_acc: {train_acc:.4f} | \"\n",
        "            f\"test_loss: {test_loss:.4f} | \"\n",
        "            f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # 5. Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        \n",
        "        model_save_path = 'Saved Models/VGGNETINSPIRED_replica_epoch' +str(epoch+1) + '.pth'\n",
        "        torch.save(model.state_dict(), model_save_path)\n",
        "    # 6. Return the filled results at the end of the epochs\n",
        "    return results\n",
        "\n"
      ],
      "metadata": {
        "id": "tmkzLkcNOoRI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Begin training and record metrics such as train/test accuracy and loss"
      ],
      "metadata": {
        "id": "5nKT992XTiFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "results = train(model=m2,train_dataloader = train_loader,test_dataloader=test_loader,\n",
        "      optimizer = opt, loss_fn=loss_fn,epochs=25, device=device)\n",
        "end = time.time()\n",
        "print(f' Time took  {(end - start)/60}  minutes')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461,
          "referenced_widgets": [
            "dd96f9698d454c92aec9640c95e2b22c",
            "ba1274028ee9487ea2d3c4bd6a07081b",
            "285500f48bfd4deb814695769b65ad1d",
            "0d1f76f7ee9a4b25bdf5dc889052844a",
            "f96c50e09b3f463a8fadd866ac44a7ec",
            "314cead0203745329eb205ee89332d7b",
            "511045e3afa34789bdf1844f526fe661",
            "24717b7cd6394dc1abe1cc8e711333bf",
            "4632362dc15d4e919ec9924ad44752fb",
            "ab032c17d34b4387acf591dbb6b3f190",
            "e04e14c6fb1d4323948076a47a0989c4"
          ]
        },
        "id": "iQ-kYi1xPiiU",
        "outputId": "52c6a43c-9158-4388-bd8e-fa0afc3322b0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dd96f9698d454c92aec9640c95e2b22c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 0.9995 | train_acc: 0.7080 | test_loss: 0.2981 | test_acc: 0.9187\n",
            "Epoch: 2 | train_loss: 0.1855 | train_acc: 0.9451 | test_loss: 0.2293 | test_acc: 0.9350\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-0a2b93e9fc11>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m results = train(model=m2,train_dataloader = train_loader,test_dataloader=test_loader,\n\u001b[0m\u001b[1;32m      3\u001b[0m       optimizer = opt, loss_fn=loss_fn,epochs=25, device=device)\n\u001b[1;32m      4\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf' Time took  {(end - start)/60}  minutes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-5c8b3caa0452>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, test_dataloader, optimizer, device, loss_fn, epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# 3. Loop through training and testing steps for a number of epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         train_loss, train_acc = train_step(model=model,\n\u001b[0m\u001b[1;32m     20\u001b[0m                                            \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                                            \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-3eb2f34e5c34>\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(model, opt, loss_fn, train_dataloader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Create files needed for Deployment on Hugging Face using Gradio###"
      ],
      "metadata": {
        "id": "GTFequZNSRPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deployment_path = Path('Deployment')\n",
        "deployment_path.mkdir(parents=True,exist_ok=True)"
      ],
      "metadata": {
        "id": "ty8ByxjpT6yK"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Deployment/class_names.txt\n",
        "Ahead only\n",
        "Beware of ice or snow\n",
        "Bicycles crossing\n",
        "Bumpy road\n",
        "Children crossing\n",
        "Dangerous curve left\n",
        "Dangerous curve right\n",
        "Double curve\n",
        "End no passing veh > 3.5 tons\n",
        "End of no passing\n",
        "End of speed limit (80kmh)\n",
        "End speed + passing limits\n",
        "General caution\n",
        "Go straight or left\n",
        "Go straight or right\n",
        "Keep left\n",
        "Keep right\n",
        "No entry\n",
        "No passing\n",
        "No passing veh over 3.5 tons\n",
        "No vehicles\n",
        "Pedestrians\n",
        "Priority road\n",
        "Right-of-way at intersection\n",
        "Road narrows on the right\n",
        "Road work\n",
        "Roundabout mandatory\n",
        "Slippery road\n",
        "Speed limit (100kmh)\n",
        "Speed limit (120kmh)\n",
        "Speed limit (20kmh)\n",
        "Speed limit (30kmh)\n",
        "Speed limit (50kmh)\n",
        "Speed limit (60kmh)\n",
        "Speed limit (70kmh)\n",
        "Speed limit (80kmh)\n",
        "Stop\n",
        "Traffic signals\n",
        "Turn left ahead\n",
        "Turn right ahead\n",
        "Veh > 3.5 tons prohibited\n",
        "Wild animals crossing\n",
        "Yield"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzsPWUFoUQb2",
        "outputId": "75a4d20e-c3ea-4d69-dde4-d2c6fd48ed42"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Deployment/class_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Deployment/requirements.txt\n",
        "torch==1.12.0\n",
        "torchvision==0.13.0\n",
        "gradio==3.1.4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RE1Vwvr1T4wv",
        "outputId": "89cd2cc1-5a8d-45fd-b9c5-354a764bd5e4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Deployment/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Deployment/app.py \n",
        "\n",
        "### 1. Imports and class names setup ### \n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "from create_model import create_CNN\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "# Setup class names\n",
        "with open(\"class_names.txt\", \"r\") as f: # reading them in from class_names.txt\n",
        "    class_names = [food_name.strip() for food_name in  f.readlines()]\n",
        "    \n",
        "### 2. Model and transforms preparation ###    \n",
        "\n",
        "# Create model\n",
        "model = create_CNN()\n",
        "\n",
        "# Load saved weights\n",
        "model.load_state_dict(\n",
        "    torch.load(\n",
        "        f=\"model_adam_epoch25.pth\",\n",
        "        map_location=torch.device(\"cpu\"),  # load to CPU because gpu not guaranteed\n",
        "    )\n",
        ")\n",
        "\n",
        "### 3. Predict function ###\n",
        "\n",
        "# Create predict function\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    # Start the timer\n",
        "    start_time = timer()\n",
        "    t = transforms.Compose([\n",
        "        transforms.Resize(size=(32,32)),\n",
        "        transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "    # Transform the target image and add a batch dimension\n",
        "    img = t(img).unsqueeze(0)\n",
        "    \n",
        "    # Put model into evaluation mode and turn on inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "        pred_probs = torch.softmax(model(img), dim=1)\n",
        "    \n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "    \n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "    \n",
        "    # Return the prediction dictionary and prediction time \n",
        "    return pred_labels_and_probs, pred_time\n",
        "\n",
        "### 4. Gradio app ###\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"GTSRB - German Traffic Sign Recognition by Tenzin Nanglo\"\n",
        "description = \"CNN created for the GTSRB Dataset, achieved 98% test accuracy\"\n",
        "article = \"Created a 3 block CNN consisting of two convolutional blocks and one classifier block. The model was trained on 25 epochs and a batch size of 32 using an Adam Optimizer with a learning rate of .001. The design of the CNN architecture was inspired by other projects conducted on this dataset. There were no additional preprocessing procedures done on the data besides resizing them into 32x32 images.\"\n",
        "\n",
        "# Create examples list from \"examples/\" directory\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(\"examples\")]\n",
        "\n",
        "# Create Gradio interface \n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
        "        gr.Number(label=\"Prediction time (s)\"),\n",
        "    ],\n",
        "    examples=example_list,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        ")\n",
        "\n",
        "# Launch the app!\n",
        "demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7P-tDYGSFAE",
        "outputId": "092ff614-a23b-4a1c-ccb5-b8e5bb16eac9"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Deployment/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Deployment/model_class.py \n",
        "from torch import nn\n",
        "\n",
        "class CNNTraffic(nn.Module):\n",
        "    def __init__(self,input_shape:int,output_shape:int):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = input_shape, out_channels = 32, kernel_size=5, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=5, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 2),\n",
        "          nn.Dropout(p=.25)\n",
        "          )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "          nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size=3, stride=1, padding=1),\n",
        "          nn.ReLU(),\n",
        "          nn.MaxPool2d(kernel_size = 2),\n",
        "          nn.Dropout(p=.25))\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "          nn.Flatten(),\n",
        "          nn.Linear(in_features=3136,out_features=256),\n",
        "          nn.Dropout(p=.5),\n",
        "          nn.Linear(in_features=256,out_features=output_shape))\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.fc(self.layer2(self.layer1(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcOK-FvhTwhF",
        "outputId": "6a5218ce-ecd6-4660-a268-3650e10be45d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Deployment/model_class.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Deployment/create_model.py\n",
        "import torch\n",
        "import torchvision\n",
        "from model_class import CNNTraffic\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "def create_CNN(seed:int=42):\n",
        "\n",
        "    model = CNNTraffic(input_shape=3,output_shape=43)\n",
        "\n",
        "    \n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    \n",
        "    \n",
        "    \n",
        "    return model\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUp8VCsmTtXG",
        "outputId": "4dd4bfec-10cf-40a7-ddf3-ca5b7014188b"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Deployment/create_model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Make an examples folder and add three images from test set to examples\n",
        "examples_path = deployment_path / 'examples'\n",
        "examples_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "examples = [Path('/content/Data/Test/Ahead only/00009.png'),\n",
        "                            Path('/content/Data/Test/Beware of ice or snow/00041.png'),\n",
        "                            Path('/content/Data/Test/Beware of ice or snow/00443.png')]\n",
        "\n",
        "#Copy the three random images to the examples directory\n",
        "for example in examples:\n",
        "    destination = examples_path / example.name\n",
        "    print(f\"[INFO] Copying {example} to {destination}\")\n",
        "    shutil.copy2(src=example, dst=destination)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKxPgHLZWlAL",
        "outputId": "9e9e999d-16e5-48a2-f336-608e399fe4c0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Copying /content/Data/Test/Ahead only/00009.png to Deployment/examples/00009.png\n",
            "[INFO] Copying /content/Data/Test/Beware of ice or snow/00041.png to Deployment/examples/00041.png\n",
            "[INFO] Copying /content/Data/Test/Beware of ice or snow/00443.png to Deployment/examples/00443.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Zip all files related to deployment and download the zip file \n",
        "!cd Deployment/ && zip -r Deployment * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "files.download(\"Deployment/Deployment.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "DOdWjRlDUml-",
        "outputId": "e342d3bb-408f-4824-e4b3-264c14f1a783"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: app.py (deflated 54%)\n",
            "updating: class_names.txt (deflated 53%)\n",
            "updating: create_model.py (deflated 45%)\n",
            "updating: model_class.py (deflated 70%)\n",
            "updating: requirements.txt (deflated 4%)\n",
            "  adding: examples/ (stored 0%)\n",
            "  adding: examples/00443.png (stored 0%)\n",
            "  adding: examples/00041.png (stored 0%)\n",
            "  adding: examples/00009.png (deflated 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f9015df6-cb15-4633-8131-3d5a5624c026\", \"Deployment.zip\", 25215)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}